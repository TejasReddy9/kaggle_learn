{"cells":[{"metadata":{"_uuid":"b6269c0e8f417f82daf093dda8fa0da6d2c57d86","_cell_guid":"e81ee64d-e474-4662-9036-ce23df615199"},"cell_type":"markdown","source":"# Introduction\n**This is the workspace for the [Machine Learning course](https://www.kaggle.com/learn/machine-learning).**\n\nI've translated the concepts to work with the data in this notebook, the Iowa data. Each page in the Machine Learning course includes instructions for what code to write at that step in the course.\n\n# Iowa Housing price prediction"},{"metadata":{"_uuid":"a6a3978945ecaf952d6add94e243da1d6f8b375e"},"cell_type":"markdown","source":"These are the modules you need."},{"metadata":{"_uuid":"1c728098629e1301643443b1341556a15c089b2b","_cell_guid":"86b26423-563a-4fa1-a595-89e25ff93089","trusted":true,"collapsed":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.preprocessing import Imputer, OneHotEncoder\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, GradientBoostingClassifier\nfrom sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\nfrom sklearn.pipeline import make_pipeline\nfrom xgboost import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56ee4303873bcea8bb755506c6ec70fa6cb9fab5","_kg_hide-output":false},"cell_type":"code","source":"data = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ntest_data = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\nprint(data.describe())\nprint(test_data.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf88575c47c4a711efa35998d5fbc852d15c059b"},"cell_type":"code","source":"print(data.columns)\nprint(test_data.columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87be07f29bb79251eef77c09f3e5d5f0266d2266"},"cell_type":"markdown","source":"Our target column is SalePrice."},{"metadata":{"trusted":true,"_uuid":"9bda047e6ab9d81d7161a2376117960c231ce1a6","_kg_hide-output":false},"cell_type":"code","source":"y = data.SalePrice\nprint(y.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9600cc4b064b4b8b9eb4c49bad15f474c7b37767"},"cell_type":"code","source":"X = data.drop(['SalePrice','Id'], axis=1)\ntest_data_bak = test_data.copy()\nprint(test_data_bak.shape)\ntest_data = test_data.drop(['Id'], axis=1)\nprint(X.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d25aa49cba1eb769a4ae0817b2ebda36bd56137e"},"cell_type":"markdown","source":"Check datatypes of all the columns."},{"metadata":{"trusted":true,"_uuid":"ced536ba773820ab8246b81f698593b77181b644"},"cell_type":"code","source":"print(X.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5070782838d3eab1ede46507af029b1f71243f0a"},"cell_type":"markdown","source":"Let's handle for missing data."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5df8f51a4b2eefffc1a22582a637de1ba0810e45"},"cell_type":"code","source":"missing_cols = [col for col in X.columns if X[col].isnull().any()]\nX = X.drop(missing_cols, axis=1)\ntest_data = test_data.drop(missing_cols, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96a4c4748587f0e0634b716daa297663f79126c4"},"cell_type":"markdown","source":"We should convert the categorical data, i.e., object datatypes into numerical data. It might contain important useful features. The number of categories in a categorical column shouldn't be too high, it may lead to overfitting. "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"995d874241c8268290ef0cf81dda23c2014633db"},"cell_type":"code","source":"numeric_cols = [col for col in X.columns if X[col].dtype in ['int64','float64']]\nlow_cardinality_cols = [col for col in X.columns if X[col].nunique() < 10 and X[col].dtype == 'object']\ntrain_X = X[numeric_cols + low_cardinality_cols]\ntest_X = test_data[numeric_cols + low_cardinality_cols] ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56a8781819b81ca1d17bc5dfb8449090ee60ad2f"},"cell_type":"markdown","source":"Let's get dummies."},{"metadata":{"trusted":true,"_uuid":"f23371794b365c8a6bc31fe8fa9cd15ed11f9476"},"cell_type":"code","source":"train_X_dummies = pd.get_dummies(train_X)\ntest_X_dummies = pd.get_dummies(test_X)\nprint(train_X_dummies.shape)\nprint(test_X_dummies.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ffd094927265605ccecd9919286b31b5f26f4c48"},"cell_type":"markdown","source":"We need to make the number of columns same for making them usable by the model."},{"metadata":{"trusted":true,"_uuid":"2e0f5242aeeceb7428ab746ad3452ca1013d96e4"},"cell_type":"code","source":"final_train, final_test = train_X_dummies.align(test_X_dummies, join=\"inner\", axis=1)\nprint(final_train.shape)\nprint(final_test.shape)\nprint(final_train.columns)\nprint(final_test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c6b099ddee3d379f5646660d084df3d1dee7c2a5"},"cell_type":"markdown","source":"Function for finding MAE through Cross Validation Scores."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0dd01119aa2eba57cb25b0fb8e13988d217a20ce"},"cell_type":"code","source":"def get_mae_by_cv(X, y):\n    return (-1)*cross_val_score(RandomForestRegressor(50), X, y, scoring=\"neg_mean_absolute_error\").mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0fd68735f46844bd060c1d7e61127fcd1c467ac"},"cell_type":"code","source":"print(get_mae_by_cv(final_train, y))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce393735546445882bb54c8e1570b597460a12ea"},"cell_type":"markdown","source":"We can use pipelines instead of the commented lines above for imputing."},{"metadata":{"trusted":true,"_uuid":"d6e91ec6e36e6467085014244ed3cde22bbca4b0"},"cell_type":"code","source":"xgb_pipeline = make_pipeline(Imputer(), XGBRegressor())\nxgb_pipeline.fit(final_train, y)\ncv_results_xgb = (-1)*cross_val_score(xgb_pipeline, final_train, y, scoring=\"neg_mean_absolute_error\").mean()\nprint(\"XGB\",cv_results_xgb)\nxgb_pipeline_parameterized = make_pipeline(Imputer(), XGBRegressor(n_estimators=135, learning_rate=0.05))\nxgb_pipeline_parameterized.fit(final_train, y)\ncv_results_xgb_parameterized = (-1)*cross_val_score(xgb_pipeline_parameterized, final_train, y, scoring=\"neg_mean_absolute_error\").mean()\nprint(\"XGB_parameterized\",cv_results_xgb_parameterized)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4d318bebd9cddbd5a5b51e5c134abd49a064e3c"},"cell_type":"markdown","source":"Let's predict."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"60922bc6e34e661260c79f82ae09564f49137e40"},"cell_type":"code","source":"predicted_values = xgb_pipeline_parameterized.predict(final_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d433a58efe39b41d192f6ea58aa54c9eea772b3"},"cell_type":"code","source":"print(*list(final_train.columns),sep='\\n') #LotArea, OverallQual, YearBuilt\nanalyse_these_cols = ['LotArea','OverallQual','YearBuilt']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b88ddfb77b550e94a9e5027a27a637df276ec1cc"},"cell_type":"markdown","source":"We can only plot dependency graphs if we had already modelled and fitted our training data w.r.t. those features to be examined. And, let's use pipelines."},{"metadata":{"trusted":true,"_uuid":"630edb2ed92027ff0bdc823a2fc9699884de554e"},"cell_type":"code","source":"training_col_under_analysis = final_train[analyse_these_cols]\ngbmodel = GradientBoostingRegressor()\ngb_pipeline = make_pipeline(Imputer(), gbmodel)\ngb_pipeline.fit(training_col_under_analysis, y)\nplots = plot_partial_dependence(gbmodel, \n                                features=[0,1,2], \n                                X = training_col_under_analysis, \n                                feature_names = analyse_these_cols, \n                                grid_resolution=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa55bac44d5808059abdd4b685768b5c67cd53f9","collapsed":true},"cell_type":"code","source":"my_submission = pd.DataFrame({'Id': test_data_bak.Id, 'SalePrice': predicted_values})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d869fbaabcde5bd0831dd8a1167790eeed282f62","collapsed":true},"cell_type":"code","source":"my_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64fde43ae8511da761549c42f24eccb5d1039271","_cell_guid":"06a2e301-f224-40d0-8709-a942b24cd124"},"cell_type":"markdown","source":"**Ask me in case if you needed any help. **\n\n**Check the course contents. [ML Course Index](https://www.kaggle.com/learn/machine-learning)**"},{"metadata":{"_uuid":"704e07440d7d4ef7ad3cf25c0a966c000bb8eeef","_cell_guid":"895df7f1-dab8-4c54-ab7e-9a865146deac"},"cell_type":"markdown","source":""}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}
