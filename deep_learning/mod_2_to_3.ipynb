{"cells":[{"metadata":{"_cell_guid":"0d1f1ae3-b33b-401f-9ef9-2e5b82c646e2","_uuid":"27211f955633b53c08ce066e9356b0338efa6184"},"cell_type":"markdown","source":"# Exercise Introduction - Hot dog, Not hot dog\n\nThe TV show *Silicon Valley* had an app called \"See Food\" that promised to identify food in pictures (demo of the app [in this tense scene](https://www.youtube.com/watch?v=ACmydtFDTGs)). \n\nA pre-trained model and TensorFlow are used to build the engine for this app."},{"metadata":{"_cell_guid":"416947b2-3a72-4788-80c8-fa491b0bd792","_uuid":"25ee821545bc547630ed14904388cabf42b95945"},"cell_type":"markdown","source":"# 1) Create Image Paths\nLet's take image files to examine. Let's store the filepaths with the name `image_paths`."},{"metadata":{"_cell_guid":"21ada0e3-34c7-4612-ad76-f2d94bada1de","_uuid":"bca8000113fc44914e73ac1180989ce0ec6a731a","collapsed":true,"trusted":true},"cell_type":"code","source":"from os.path import join\n\nhot_dog_image_dir = '../input/hot-dog-not-hot-dog/seefood/train/hot_dog'\n\nhot_dog_paths = [join(hot_dog_image_dir,filename) for filename in \n                            ['1000288.jpg',\n                             '127117.jpg']]\n\nnot_hot_dog_image_dir = '../input/hot-dog-not-hot-dog/seefood/train/not_hot_dog'\nnot_hot_dog_paths = [join(not_hot_dog_image_dir, filename) for filename in\n                            ['823536.jpg',\n                             '99890.jpg']]\n\nimage_paths = hot_dog_paths + not_hot_dog_paths","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"01ac41e4-b222-47a8-927b-af25b3de05b6","_uuid":"d1b7e7af3ae93027e31e0f89d23588dfd3483906"},"cell_type":"markdown","source":"# 2) Set Up Preprocessing\nCreating `read_and_prep_images` function, for storing in numpy array data just like we work with tabular data in pandas."},{"metadata":{"_cell_guid":"7de28235-8b6f-4fcf-94db-7e3947e73d53","_uuid":"21f3bf50d3dc5d5bc2ffb380a937d6ba32f9ef41","trusted":true},"cell_type":"code","source":"import numpy as np\nfrom tensorflow.python.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.python.keras.applications import ResNet50\nfrom tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n\nimage_size = 224\n\ndef read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n    imgs = [load_img(image_path, target_size=(img_height, img_width)) for image_path in image_paths]\n    img_data = np.array([img_to_array(img) for img in imgs])\n    return preprocess_input(img_data)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"93800ce8-19a8-43b4-a152-6eb32eb0e106","_uuid":"2b76f3fabd1b95bdfbe22850951530506edb4d27"},"cell_type":"markdown","source":"# 3) Modeling\nNow, create a Resnet50 model and save it as `model`.\nApply the `read_and_prep_images` function to `image_paths` and save the result as `img_test_data`.\nUse `model` to predict the contents of `img_test_data`.  Store the results in `predictions`.\nYou can review the instructional page to remind yourself how to do this."},{"metadata":{"_cell_guid":"6dffaa68-3629-4b62-bd34-a259a5a4e7bd","_uuid":"640e851efdccee95f41de83a213fc2f5c6e77b6a","trusted":true},"cell_type":"code","source":"import sys\nsys.path.append(\"../input/python-utility-code-for-deep-learning-exercises/utils/\")\nfrom decode_predictions import decode_predictions\n\nmodel = ResNet50(weights=\"../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5\")\nimg_test_data = read_and_prep_images(image_paths, image_size, image_size)\npredictions = model.predict(img_test_data)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5ebe832b-bf25-458e-8720-9797382237e3","_uuid":"ea9256f687184d8f73c48edda5b9fc9833fec91e"},"cell_type":"markdown","source":"# 4) Visualize Your Results\n\nApply the `decode_predictions` function to `predictions`.  We could focus on just the top prediction for each image with the argument `top=1`.\n"},{"metadata":{"_cell_guid":"51bb265c-1853-4f40-af58-3c761df52a0b","_uuid":"4e1b5106b5ab9b74ee73a1b4c3b0458cbd78573a"},"cell_type":"markdown","source":"Importing the `decode predictions` function we use to get the top labels. TensorFlow includes an alternative version of this function, but we'll use a version optimized for running on Kaggle Kernels."},{"metadata":{"_cell_guid":"459d46ab-2cee-492b-bc73-a9b375394f25","_uuid":"7128928a6d61e28d2c6b8d9a86a899696ee5445c","collapsed":true,"trusted":true},"cell_type":"code","source":"import sys\nfrom learntools.deep_learning.decode_predictions import decode_predictions\n\npredicted_highest_accurate_label = decode_predictions(predictions, top=1, class_list_path=\"../input/resnet50/imagenet_class_index.json\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"037a8053-56c6-411c-b841-51f20f7c4289","_uuid":"deacd232ce00c259e8f5d0d68102024b44168dc8"},"cell_type":"markdown","source":"Let's display our results."},{"metadata":{"_cell_guid":"6acdf242-f174-43aa-97e3-d4ef721600e5","_uuid":"405653355f697903a0d9ca14d5e51f34cac4da83","trusted":true},"cell_type":"code","source":"from IPython.display import Image, display\n\nfor i, img_path in enumerate(image_paths):\n    display(Image(img_path))\n    print(predicted_highest_accurate_label[i])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"30d6196c-58db-4724-84a4-e0465c222067","_uuid":"730211d6eac2bf6d9e58bfd17524b6facc0b9748"},"cell_type":"markdown","source":"# Keep Going\n**You are ready for [Transfer Learning](https://www.kaggle.com/dansbecker/transfer-learning/), which will allow you to apply the same level of power for your custom purposes.**\n\n---\n**[Deep Learning Track Home](https://www.kaggle.com/learn/deep-learning)**"}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}
